D:\thesis\sss\model.py:64: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\cb\pytorch_1000000000000\work\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:455.)
  y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True)
step 0: train loss 4.2874, val loss 4.2823
GPU Memory before iteration 0:
  Total: 4.29 GB
  Reserved: 0.31 GB
  Allocated: 0.05 GB
  Free: 3.98 GB
  Estimated memory for this iteration: 0.07 GB
iter 0: loss 4.2669, time 18578.89ms, mfu -100.00%
Time stamp: 2024-07-19 17:06:47, Time since last checkpoint: 0:00:18
GPU Memory before iteration 10:
  Total: 4.29 GB
  Reserved: 1.80 GB
  Allocated: 0.15 GB
  Free: 2.50 GB
  Estimated memory for this iteration: 0.07 GB
iter 10: loss 3.2431, time 421.17ms, mfu 0.88%
Time stamp: 2024-07-19 17:06:49, Time since last checkpoint: 0:00:01
GPU Memory before iteration 20:
  Total: 4.29 GB
  Reserved: 1.80 GB
  Allocated: 0.15 GB
  Free: 2.50 GB
  Estimated memory for this iteration: 0.07 GB
iter 20: loss 2.7743, time 428.45ms, mfu 0.88%
Time stamp: 2024-07-19 17:06:50, Time since last checkpoint: 0:00:01
GPU Memory before iteration 30:
  Total: 4.29 GB
  Reserved: 1.80 GB
  Allocated: 0.15 GB
  Free: 2.50 GB
  Estimated memory for this iteration: 0.07 GB
iter 30: loss 2.6385, time 414.49ms, mfu 0.88%
Time stamp: 2024-07-19 17:06:52, Time since last checkpoint: 0:00:01
GPU Memory before iteration 40:
  Total: 4.29 GB
  Reserved: 1.80 GB
  Allocated: 0.15 GB
  Free: 2.50 GB
  Estimated memory for this iteration: 0.07 GB
iter 40: loss 2.5788, time 424.72ms, mfu 0.88%
Time stamp: 2024-07-19 17:06:53, Time since last checkpoint: 0:00:01
GPU Memory before iteration 50:
  Total: 4.29 GB
  Reserved: 1.80 GB
  Allocated: 0.15 GB
  Free: 2.50 GB
  Estimated memory for this iteration: 0.07 GB
iter 50: loss 2.5291, time 422.13ms, mfu 0.88%
Time stamp: 2024-07-19 17:06:55, Time since last checkpoint: 0:00:01
GPU Memory before iteration 60:
  Total: 4.29 GB
  Reserved: 1.80 GB
  Allocated: 0.15 GB
  Free: 2.50 GB
  Estimated memory for this iteration: 0.07 GB
iter 60: loss 2.5122, time 426.47ms, mfu 0.88%
Time stamp: 2024-07-19 17:06:56, Time since last checkpoint: 0:00:01
GPU Memory before iteration 70:
  Total: 4.29 GB
  Reserved: 1.80 GB
  Allocated: 0.15 GB
  Free: 2.50 GB
  Estimated memory for this iteration: 0.07 GB
iter 70: loss 2.5016, time 427.99ms, mfu 0.88%
Time stamp: 2024-07-19 17:06:57, Time since last checkpoint: 0:00:01
Traceback (most recent call last):
  File "D:\thesis\sss\train.py", line 340, in <module>
    scaler.scale(loss).backward()
  File "C:\Users\Ronald\miniconda3\envs\torchenv\lib\site-packages\torch\_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "C:\Users\Ronald\miniconda3\envs\torchenv\lib\site-packages\torch\autograd\__init__.py", line 267, in backward
    _engine_run_backward(
  File "C:\Users\Ronald\miniconda3\envs\torchenv\lib\site-packages\torch\autograd\graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt